{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCnywixVLC-z"
      },
      "source": [
        "# Image Segmentation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ei0_O5FPg4ye"
      },
      "outputs": [],
      "source": [
        "pip install tensorflow-addons\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4OWfNcNGSUSL"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "import tensorflow.keras.models as models\n",
        "import tensorflow.keras.backend as K\n",
        "import tensorflow.keras.layers as layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping, CSVLogger\n",
        "from tensorflow.keras.models import load_model, Model\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import requests\n",
        "import zipfile\n",
        "import pickle\n",
        "import time\n",
        "import random\n",
        "import shutil\n",
        "import glob\n",
        "import tarfile\n",
        "from PIL import Image\n",
        "from PIL.PngImagePlugin import PngImageFile\n",
        "from functools import partial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xcd60wjNLC-5"
      },
      "outputs": [],
      "source": [
        "available_gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if available_gpus:\n",
        "    try:\n",
        "        for gpu in available_gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    except Exception as e:\n",
        "        print(\"Не вдалося налаштувати пам'ять для GPU:\", e)\n",
        "def set_random_seed(seed_value):\n",
        "    try:\n",
        "        np.random.seed(seed_value)\n",
        "    except Exception as e:\n",
        "        print(\"Numpy не вдалося імпортувати.\", e)\n",
        "    try:\n",
        "        tf.random.set_seed(seed_value)\n",
        "    except Exception as e:\n",
        "        print(\"TensorFlow не вдалося імпортувати.\", e)\n",
        "    try:\n",
        "        random.seed(seed_value)\n",
        "    except Exception as e:\n",
        "        print(\"Модуль random не вдалося імпортувати\", e)\n",
        "\n",
        "random_seed = 4321\n",
        "set_random_seed(random_seed)\n",
        "print(\"Поточна версія TensorFlow: {}\".format(tf.__version__))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jVoNn03k3_7p"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists(os.path.join('data','VOCtrainval_11-May-2012.tar')):\n",
        "    url = \"http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar\"\n",
        "    r = requests.get(url)\n",
        "    if not os.path.exists('data'):\n",
        "        os.mkdir('data')\n",
        "    with open(os.path.join('data','VOCtrainval_11-May-2012.tar'), 'wb') as f:\n",
        "        f.write(r.content)\n",
        "else:\n",
        "    print(\"Файл вже існує.\")\n",
        "\n",
        "archive_path = '/content/data/VOCtrainval_11-May-2012.tar'\n",
        "extracted_dir = '/content/data/VOCtrainval_11-May-2012'\n",
        "if os.path.exists(archive_path):\n",
        "    if not os.path.exists(extracted_dir):\n",
        "        with tarfile.open(archive_path, 'r') as tar:\n",
        "            tar.extractall(extracted_dir)\n",
        "        print(\"Архів успішно розархівовано.\")\n",
        "    else:\n",
        "        print(\"Розархівована директорія вже існує.\")\n",
        "else:\n",
        "    print(\"Файл архіву не знайдено.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEhop799FDRV"
      },
      "source": [
        "##Завантаження даних\n",
        "##Аугментація зображення"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJ2bKdIqN0hN"
      },
      "outputs": [],
      "source": [
        "def get_subset_filenames(orig_dir, seg_dir, subset_dir, subset):\n",
        "    if subset.startswith('train'):\n",
        "        ser = pd.read_csv(os.path.join(subset_dir, \"train.txt\"), header=None).squeeze().tolist()\n",
        "    elif subset.startswith('val') or subset.startswith('test'):\n",
        "        random.seed(random_seed)\n",
        "        ser = pd.read_csv(os.path.join(subset_dir, \"val.txt\"), header=None).squeeze().tolist()\n",
        "        random.shuffle(ser)\n",
        "        if subset.startswith('val'):\n",
        "            ser = ser[:len(ser)//2]\n",
        "        else:\n",
        "            ser = ser[len(ser)//2:]\n",
        "    else:\n",
        "        raise NotImplementedError(\"Subset={} не розпізнана\".format(subset))\n",
        "\n",
        "    orig_filenames = [os.path.join(orig_dir, f'{f}.jpg') for f in ser]\n",
        "    seg_filenames = [os.path.join(seg_dir, f'{f}.png') for f in ser]\n",
        "\n",
        "    for o, s in zip(orig_filenames, seg_filenames):\n",
        "        yield o, s\n",
        "\n",
        "def image_loader(image):\n",
        "    img = np.array(Image.open(image))\n",
        "    img[img == 255] = 0\n",
        "    return img\n",
        "\n",
        "def adjust_shape(x, y, target_size):\n",
        "    x.set_shape((target_size[0], target_size[1], 3))\n",
        "    y.set_shape((target_size[0], target_size[1], 1))\n",
        "    return x, y\n",
        "\n",
        "def generate_tf_dataset(\n",
        "    subset_filename_gen_func, batch_size, epochs,\n",
        "    input_size=(256, 256),  resize_to_before_crop=None,\n",
        "    augmentation=False\n",
        "):\n",
        "\n",
        "    filename_ds = tf.data.Dataset.from_generator(\n",
        "        subset_filename_gen_func, output_types=(tf.string, tf.string)\n",
        "    )\n",
        "\n",
        "    image_ds = filename_ds.map(lambda x, y: (\n",
        "        tf.image.decode_jpeg(tf.io.read_file(x)),\n",
        "        tf.numpy_function(image_loader, [y], [tf.uint8])\n",
        "    )).cache()\n",
        "    image_ds = image_ds.map(lambda x, y: (tf.cast(x, 'float32')/255.0, y))\n",
        "\n",
        "    def crop_or_resize_randomly(x, y):\n",
        "        rand = tf.random.uniform([], 0.0, 1.0)\n",
        "        def random_crop(x, y):\n",
        "            x = tf.image.resize(x, resize_to_before_crop, method='bilinear')\n",
        "            y = tf.cast(tf.image.resize(tf.transpose(y, [1, 2, 0]), resize_to_before_crop, method='nearest'), 'float32')\n",
        "\n",
        "            offset_h = tf.random.uniform([], 0, x.shape[0]-input_size[0], dtype='int32')\n",
        "            offset_w = tf.random.uniform([], 0, x.shape[1]-input_size[1], dtype='int32')\n",
        "\n",
        "            x = tf.image.crop_to_bounding_box(x, offset_h, offset_w, input_size[0], input_size[1])\n",
        "            y = tf.image.crop_to_bounding_box(y, offset_h, offset_w, input_size[0], input_size[1])\n",
        "            return x, y\n",
        "\n",
        "        def resize(x, y):\n",
        "            x = tf.image.resize(x, input_size, method='bilinear')\n",
        "            y = tf.cast(tf.image.resize(tf.transpose(y, [1, 2, 0]), input_size, method='nearest'), 'float32')\n",
        "            return x, y\n",
        "\n",
        "        if augmentation and (input_size[0] < resize_to_before_crop[0] or input_size[1] < resize_to_before_crop[1]):\n",
        "            x, y = tf.cond(\n",
        "                rand < 0.5,\n",
        "                lambda: random_crop(x, y),\n",
        "                lambda: resize(x, y)\n",
        "            )\n",
        "        else:\n",
        "            x, y = resize(x, y)\n",
        "\n",
        "        return x, y\n",
        "\n",
        "    image_ds = image_ds.map(lambda x, y: crop_or_resize_randomly(x, y))\n",
        "    image_ds = image_ds.map(lambda x, y: adjust_shape(x, y, target_size=input_size))\n",
        "\n",
        "    if augmentation:\n",
        "        image_ds = image_ds.map(lambda x, y: (tf.image.random_hue(x, 0.1), y))\n",
        "        image_ds = image_ds.map(lambda x, y: (tf.image.random_brightness(x, 0.1), y))\n",
        "        image_ds = image_ds.map(lambda x, y: (tf.image.random_contrast(x, 0.8, 1.2), y))\n",
        "\n",
        "    image_ds = image_ds.batch(batch_size).repeat(epochs)\n",
        "    image_ds = image_ds.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "    image_ds = image_ds.map(lambda x, y: (x, tf.squeeze(y)))\n",
        "    return image_ds\n",
        "\n",
        "orig_dir = os.path.join('data', 'VOCtrainval_11-May-2012', 'VOCdevkit', 'VOC2012', 'JPEGImages')\n",
        "seg_dir = os.path.join('data', 'VOCtrainval_11-May-2012', 'VOCdevkit', 'VOC2012', 'SegmentationClass')\n",
        "subset_dir = os.path.join('data', 'VOCtrainval_11-May-2012', 'VOCdevkit', 'VOC2012', 'ImageSets', \"Segmentation\")\n",
        "\n",
        "\n",
        "partial_subset_fn = partial(get_subset_filenames, orig_dir=orig_dir, seg_dir=seg_dir, subset_dir=subset_dir)\n",
        "train_subset_fn = partial(partial_subset_fn, subset='train')\n",
        "val_subset_fn = partial(partial_subset_fn, subset='val')\n",
        "test_subset_fn = partial(partial_subset_fn, subset='test')\n",
        "\n",
        "tr_image_ds = generate_tf_dataset(train_subset_fn, 2, 1)\n",
        "val_image_ds = generate_tf_dataset(val_subset_fn, 2, 1)\n",
        "\n",
        "tr_image_ds_no_aug = generate_tf_dataset(train_subset_fn, batch_size=2, epochs=1, augmentation=False)\n",
        "tr_image_ds_aug = generate_tf_dataset(train_subset_fn, batch_size=2, epochs=1, augmentation=True, resize_to_before_crop=(300, 300))\n",
        "\n",
        "orig_images, orig_targets = next(iter(tr_image_ds_no_aug.take(-2)))\n",
        "aug_images, aug_targets = next(iter(tr_image_ds_aug.take(-2)))\n",
        "\n",
        "def display_images(original, augmented):\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(10, 10))\n",
        "    for i in range(2):\n",
        "        axes[i, 0].imshow(original[i])\n",
        "        axes[i, 0].set_title('Оригінальне зображення')\n",
        "        axes[i, 0].axis('off')\n",
        "\n",
        "        axes[i, 1].imshow(augmented[i])\n",
        "        axes[i, 1].set_title('Аугментоване зображення')\n",
        "        axes[i, 1].axis('off')\n",
        "    plt.show()\n",
        "\n",
        "display_images(orig_images.numpy()[-2:],  aug_images.numpy()[-2:])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ccqDV4FLC_C"
      },
      "source": [
        "\n",
        "\n",
        "##Перетворення у RGB зображення\n",
        "##Вивід результату завантажених даних\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BAfDZcT9LC_C"
      },
      "outputs": [],
      "source": [
        "def rgb_image_from_pallette(image):\n",
        "    pallette = annot_image.getpalette()\n",
        "    pallette = np.array(pallette).reshape(-1,3)\n",
        "    if isinstance(image, PngImageFile):\n",
        "        h, w = image.height, image.width\n",
        "        image = np.array(image).reshape(-1)\n",
        "    elif isinstance(image, np.ndarray):\n",
        "        h, w = image.shape[0], image.shape[1]\n",
        "        image = image.reshape(-1)\n",
        "    rgb_image = np.zeros(shape=(image.shape[0],3))\n",
        "    rgb_image[(image != 0),:] = pallette[image[(image != 0)], :]\n",
        "    rgb_image = rgb_image.reshape(h, w, 3)\n",
        "    return rgb_image\n",
        "\n",
        "orig_image_path = os.path.join('data', 'VOCtrainval_11-May-2012', 'VOCdevkit', 'VOC2012', 'JPEGImages', '2011_002200.jpg')\n",
        "annot_image_path = os.path.join('data', 'VOCtrainval_11-May-2012', 'VOCdevkit', 'VOC2012', 'SegmentationClass', '2011_002200.png')\n",
        "orig_image = Image.open(orig_image_path)\n",
        "annot_image = Image.open(annot_image_path)\n",
        "tr_image_ds = generate_tf_dataset(\n",
        "    train_subset_fn, 1, 1, augmentation=True, resize_to_before_crop=(384,384))\n",
        "\n",
        "n=10\n",
        "def plot_data(image_ds, n):\n",
        "    plt.subplots(n//2, 4, figsize=(12,12))\n",
        "    for i, (img, y_true) in enumerate(tr_image_ds.take(n)):\n",
        "        y_true = y_true.numpy().astype('int')\n",
        "        y_rgb_true = rgb_image_from_pallette(y_true)\n",
        "\n",
        "        plt.subplot(n//2,4,i*2+1)\n",
        "        plt.imshow((img[0,:, :, :].numpy()*255.0).astype('uint8'))\n",
        "        plt.axis('off')\n",
        "        plt.subplot(n//2,4, i*2+2)\n",
        "        plt.imshow(y_rgb_true.astype('uint8'))\n",
        "        plt.axis('off')\n",
        "\n",
        "plot_data(tr_image_ds, n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bW94uvaFJAWT"
      },
      "source": [
        "##Завантажує зображення та їх сегментаційні мітки\n",
        "##Візуалізація вхідних даних\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bWEq89XMLC_D"
      },
      "outputs": [],
      "source": [
        "train_fn_gen = get_subset_filenames(orig_dir, seg_dir, subset_dir, 'training')\n",
        "visual_images = {}\n",
        "\n",
        "object_classes = {\n",
        "    0: \"Background\", 1: \"Aeroplane\", 2 : \"Bicycle\", 3: \"Bird\", 4: \"Boat\", 5: \"Bottle\",\n",
        "    6: \"Bus\", 7: \"Car\", 8: \"Cat\", 9: \"Chair\", 10: \"Cow\", 11: \"Dining table\",\n",
        "    12: \"Dog\", 13: \"Horse\", 14: \"Motorbike\", 15: \"Person\", 16: \"Potted plant\", 17: \"Sheep\",\n",
        "    18: \"Sofa\", 19: \"Train\", 20: \"TV/Monitor\", 255: \"Boundaries / Unknown object\"\n",
        "}\n",
        "\n",
        "for input_path, target_path in train_fn_gen:\n",
        "    input_image = np.array(Image.open(input_path))\n",
        "    target_image = np.array(Image.open(target_path))\n",
        "    major_class = np.max(target_image[(target_image != 0) & (target_image != 255)])\n",
        "\n",
        "    visual_images[major_class] = (input_image, target_image)\n",
        "    if len(visual_images) >= 20:\n",
        "        break\n",
        "\n",
        "plt.subplots(5, 8, figsize=(16, 12))\n",
        "for i, (k, v) in enumerate(sorted(visual_images.items(), key=lambda x: x[0])):\n",
        "    input_image, target_image = v\n",
        "    target_image = rgb_image_from_pallette(target_image)\n",
        "    plt.subplot(5, 8, (i * 2) + 1)\n",
        "    plt.imshow(input_image)\n",
        "    plt.title(\"{}\".format(object_classes[i + 1]))\n",
        "    plt.axis('off')\n",
        "    plt.subplot(5, 8, (i * 2) + 2)\n",
        "    plt.imshow(target_image)\n",
        "    plt.axis('off')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XXoYSOfMGTt"
      },
      "source": [
        "## Побудова моделі\n",
        "*   ResNet50\n",
        "*   ASPP\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "K.clear_session()\n",
        "num_classes = 21\n",
        "\n",
        "def create_deeplabv3(target_size):\n",
        "    def build_block_level3(inp, filters, kernel_size, rate, block_id, convlayer_id, activation=True):\n",
        "        conv_out = layers.Conv2D(\n",
        "            filters, kernel_size, dilation_rate=rate, padding='same', name='conv5_block{}_{}_conv'.format(block_id, convlayer_id)\n",
        "        )(inp)\n",
        "        bn_out = layers.BatchNormalization(\n",
        "            name='conv5_block{}_{}_bn'.format(block_id, convlayer_id)\n",
        "        )(conv_out)\n",
        "\n",
        "        if activation:\n",
        "            relu_out = layers.Activation(\n",
        "                'relu', name='conv5_block{}_{}_relu'.format(block_id, convlayer_id)\n",
        "            )(bn_out)\n",
        "            return relu_out\n",
        "        else:\n",
        "            return bn_out\n",
        "\n",
        "    def build_block_level2(inp, rate, block_id):\n",
        "        block_1_out = build_block_level3(inp, 512, (1,1), rate, block_id, 1)\n",
        "        block_2_out = build_block_level3(block_1_out, 512, (3,3), rate, block_id, 2)\n",
        "        block_3_out = build_block_level3(block_2_out, 2048, (1,1), rate, block_id, 3, activation=False)\n",
        "        return block_3_out\n",
        "\n",
        "    def build_block_level1(inp, rate):\n",
        "        block0_out = build_block_level3(inp, 2048, (1,1), 1, block_id=1, convlayer_id=0, activation=False)\n",
        "\n",
        "        block1_out = build_block_level2(inp, 2, block_id=1)\n",
        "        block1_add = layers.Add(name='conv5_block{}_add'.format(1))([block0_out, block1_out])\n",
        "        block1_relu = layers.Activation('relu', name='conv5_block{}_relu'.format(1))(block1_add)\n",
        "\n",
        "        block2_out = build_block_level2(block1_relu, 2, block_id=2)\n",
        "        block2_add = layers.Add(name='conv5_block{}_add'.format(2))([block1_add, block2_out])\n",
        "        block2_relu = layers.Activation('relu', name='conv5_block{}_relu'.format(2))(block2_add)\n",
        "\n",
        "        block3_out = build_block_level2(block2_relu, 2, block_id=3)\n",
        "        block3_add = layers.Add(name='conv5_block{}_add'.format(3))([block2_add, block3_out])\n",
        "        block3_relu = layers.Activation('relu', name='conv5_block{}_relu'.format(3))(block3_add)\n",
        "\n",
        "        return block3_relu\n",
        "\n",
        "    def atrous_spatial_pyramid_pooling(inp):\n",
        "        atrous_1_conv = build_block_level3(inp, 256, (1,1), 1, '_aspp_a', 1, activation='relu')\n",
        "        atrous_2_conv = build_block_level3(inp, 256, (3,3), 6, '_aspp_a', 2, activation='relu')\n",
        "        atrous_3_conv = build_block_level3(inp, 256, (3,3), 12, '_aspp_a', 3, activation='relu')\n",
        "        atrous_4_conv = build_block_level3(inp, 256, (3,3), 18, '_aspp_a', 4, activation='relu')\n",
        "\n",
        "        global_pooling = layers.Lambda(lambda x: K.mean(x, axis=[1,2], keepdims=True))(inp)\n",
        "        global_conv = build_block_level3(global_pooling, 256, (1,1), 1, '_aspp_b', 1, activation='relu')\n",
        "        global_up = layers.UpSampling2D((24,24), interpolation='bilinear')(global_pooling)\n",
        "        aspp_output = layers.Concatenate()([atrous_1_conv, atrous_2_conv, atrous_3_conv, atrous_4_conv, global_up])\n",
        "\n",
        "        return aspp_output\n",
        "\n",
        "    inp = layers.Input(shape=target_size + (3,))\n",
        "    resnet50_base = tf.keras.applications.ResNet50(\n",
        "        include_top=False, input_tensor=inp, pooling=None\n",
        "    )\n",
        "    for layer in resnet50_base.layers:\n",
        "        if layer.name == \"conv5_block1_1_conv\":\n",
        "            break\n",
        "        out = layer.output\n",
        "\n",
        "    resnet50_model = models.Model(resnet50_base.input, out)\n",
        "    resnet_block_output = build_block_level1(resnet50_model.output, 2)\n",
        "\n",
        "    aspp_output = atrous_spatial_pyramid_pooling(resnet_block_output)\n",
        "    final_output = layers.Conv2D(num_classes, (1,1), padding='same')(aspp_output)\n",
        "    final_output = layers.UpSampling2D((16,16), interpolation='bilinear')(final_output)\n",
        "\n",
        "    deeplabv3_model = models.Model(resnet50_model.input, final_output)\n",
        "\n",
        "    weights_dict = {}\n",
        "    for layer_name in [\"conv5_block1_0_conv\", \"conv5_block1_0_bn\",\n",
        "                       \"conv5_block1_1_conv\", \"conv5_block1_1_bn\",\n",
        "                       \"conv5_block1_2_conv\", \"conv5_block1_2_bn\",\n",
        "                       \"conv5_block1_3_conv\", \"conv5_block1_3_bn\"]:\n",
        "        weights_dict[layer_name] = resnet50_base.get_layer(layer_name).get_weights()\n",
        "\n",
        "    return deeplabv3_model, weights_dict\n"
      ],
      "metadata": {
        "id": "cdgoK3NI431t"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrzjDi8ULC_F"
      },
      "source": [
        "##Визначення функцій втрат"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "wOww3v0XPk3w"
      },
      "outputs": [],
      "source": [
        "num_classes = 21\n",
        "def get_label_weights(y_true, y_pred):\n",
        "    ignore_label = 255\n",
        "\n",
        "    mask = tf.not_equal(y_true, ignore_label)\n",
        "    y_true = tf.where(mask, y_true, tf.zeros_like(y_true))\n",
        "\n",
        "    weights = tf.reduce_sum(tf.one_hot(y_true, num_classes), axis=[1, 2])  # [b, classes]\n",
        "    tot = tf.reduce_sum(weights, axis=-1, keepdims=True)\n",
        "\n",
        "    weights = (tot - weights) / tot  # [b, classes]\n",
        "    y_true = tf.reshape(y_true, [-1, y_pred.shape[1] * y_pred.shape[2]])  # [b, -1]\n",
        "\n",
        "    y_weights = tf.gather(weights, y_true, batch_dims=1)\n",
        "    y_weights = tf.reshape(y_weights, [-1])\n",
        "    return y_weights\n",
        "def dice_loss_from_logits(num_classes):\n",
        "    def loss_fn(y_true, y_pred):\n",
        "        smooth = 1.\n",
        "        ignore_label = 255\n",
        "        y_true = tf.cast(y_true, 'int32')\n",
        "        y_true.set_shape([None, y_pred.shape[1], y_pred.shape[2]])\n",
        "\n",
        "        mask = tf.not_equal(y_true, ignore_label)\n",
        "        y_true = tf.where(mask, y_true, tf.zeros_like(y_true))\n",
        "        y_weights = tf.reshape(get_label_weights(y_true, y_pred), [-1, 1])\n",
        "        y_pred = tf.nn.softmax(y_pred)\n",
        "        y_true_unwrap = tf.reshape(y_true, [-1])\n",
        "        y_true_unwrap = tf.cast(tf.one_hot(y_true_unwrap, num_classes), 'float32')\n",
        "        y_pred_unwrap = tf.reshape(y_pred, [-1, num_classes])\n",
        "\n",
        "        intersection = tf.reduce_sum(y_true_unwrap * y_pred_unwrap * y_weights)\n",
        "        union = tf.reduce_sum((y_true_unwrap + y_pred_unwrap) * y_weights)\n",
        "        score = (2. * intersection + smooth) / (union + smooth)\n",
        "        loss = 1 - score\n",
        "        return loss\n",
        "    return loss_fn\n",
        "\n",
        "def ce_weighted_from_logits(num_classes):\n",
        "    def loss_fn(y_true, y_pred):\n",
        "        ignore_mask = tf.cast(y_true != 255, tf.float32)\n",
        "        y_true = tf.cast(y_true, tf.float32)\n",
        "        y_true_masked = y_true * ignore_mask\n",
        "        y_pred_masked = y_pred * ignore_mask[..., tf.newaxis]\n",
        "\n",
        "        loss = tf.reduce_mean(\n",
        "            tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
        "                labels=tf.cast(y_true_masked, tf.int32),\n",
        "                logits=y_pred_masked\n",
        "            )\n",
        "        )\n",
        "        return loss\n",
        "    return loss_fn\n",
        "\n",
        "def ce_dice_loss_from_logits(num_classes):\n",
        "    def loss_fn(y_true, y_pred):\n",
        "        loss = ce_weighted_from_logits(num_classes)(tf.cast(y_true, 'int32'), y_pred) + \\\n",
        "               dice_loss_from_logits(num_classes)(y_true, y_pred)\n",
        "        return loss\n",
        "    return loss_fn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mWIHuomLC_F"
      },
      "source": [
        "##Реалізація метрики оцінок"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "5C9QcICWLC_G"
      },
      "outputs": [],
      "source": [
        "class PixelAccuracyMetric(tf.keras.metrics.Accuracy):\n",
        "\n",
        "  def __init__(self, num_classes, name='pixel_accuracy', **kwargs):\n",
        "    super(PixelAccuracyMetric, self).__init__(name=name, **kwargs)\n",
        "\n",
        "  def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "\n",
        "    y_true.set_shape([None, y_pred.shape[1], y_pred.shape[2]])\n",
        "    y_true = tf.reshape(y_true, [-1])\n",
        "    y_pred = tf.reshape(tf.argmax(y_pred, axis=-1),[-1])\n",
        "\n",
        "    valid_mask = tf.reshape((y_true <= num_classes - 1), [-1])\n",
        "\n",
        "    y_true = tf.boolean_mask(y_true, valid_mask)\n",
        "    y_pred = tf.boolean_mask(y_pred, valid_mask)\n",
        "    super(PixelAccuracyMetric, self).update_state(y_true, y_pred)\n",
        "\n",
        "class MeanAccuracyMetric(tf.keras.metrics.Mean):\n",
        "  def __init__(self, num_classes, name='mean_accuracy', **kwargs):\n",
        "    super(MeanAccuracyMetric, self).__init__(name=name, **kwargs)\n",
        "\n",
        "  def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "    smooth = 1\n",
        "    y_true.set_shape([None, y_pred.shape[1], y_pred.shape[2]])\n",
        "    y_true = tf.reshape(y_true, [-1])\n",
        "    y_pred = tf.reshape(tf.argmax(y_pred, axis=-1),[-1])\n",
        "\n",
        "    valid_mask = tf.reshape((y_true <= num_classes - 1), [-1])\n",
        "\n",
        "    y_true = tf.boolean_mask(y_true, valid_mask)\n",
        "    y_pred = tf.boolean_mask(y_pred, valid_mask)\n",
        "\n",
        "    conf_matrix = tf.cast(tf.math.confusion_matrix(y_true, y_pred, num_classes=num_classes), 'float32')\n",
        "    true_pos = tf.linalg.diag_part(conf_matrix)\n",
        "    mean_accuracy = tf.reduce_mean(\n",
        "        (true_pos + smooth)/(tf.reduce_sum(conf_matrix, axis=1) + smooth)\n",
        "    )\n",
        "    super(MeanAccuracyMetric, self).update_state(mean_accuracy)\n",
        "\n",
        "class MeanIoUMetric(tf.keras.metrics.MeanIoU):\n",
        "  def __init__(self, num_classes, name='mean_iou', **kwargs):\n",
        "    super(MeanIoUMetric, self).__init__(num_classes=num_classes, name=name, **kwargs)\n",
        "\n",
        "  def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "    y_true.set_shape([None, y_pred.shape[1], y_pred.shape[2]])\n",
        "    y_true = tf.reshape(y_true, [-1])\n",
        "\n",
        "    y_pred = tf.nn.softmax(y_pred)\n",
        "    y_pred = tf.reshape(tf.argmax(y_pred, axis=-1),[-1])\n",
        "\n",
        "    valid_mask = tf.reshape((y_true <= num_classes - 1), [-1])\n",
        "\n",
        "    y_true = tf.boolean_mask(y_true, valid_mask)\n",
        "    y_pred = tf.boolean_mask(y_pred, valid_mask)\n",
        "    super(MeanIoUMetric, self).update_state(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Підготовка до навчання моделі"
      ],
      "metadata": {
        "id": "CpAHlWpuNucK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 8\n",
        "epochs = 25\n",
        "def get_steps_per_epoch(n_data, batch_size):\n",
        "    if n_data % batch_size == 0:\n",
        "        return n_data // batch_size\n",
        "    else:\n",
        "        return (n_data // batch_size) + 1\n",
        "\n",
        "train_filenames = pd.read_csv(os.path.join(subset_dir, \"train.txt\"), index_col=None, header=None).squeeze().tolist()\n",
        "val_filenames = pd.read_csv(os.path.join(subset_dir, \"val.txt\"), index_col=None, header=None).squeeze().tolist()\n",
        "\n",
        "n_train = get_steps_per_epoch(len(train_filenames), batch_size)\n",
        "n_valid = get_steps_per_epoch(len(val_filenames) // 2, batch_size)\n",
        "\n",
        "input_size = (384, 384)\n",
        "tr_image_ds = generate_tf_dataset(\n",
        "    train_subset_fn, batch_size, epochs,\n",
        "    input_size=input_size, resize_to_before_crop=(444, 444),\n",
        "    augmentation=True\n",
        ")\n",
        "val_image_ds = generate_tf_dataset(\n",
        "    val_subset_fn, batch_size, epochs,\n",
        "    input_size=input_size,\n",
        ")\n",
        "test_image_ds = generate_tf_dataset(\n",
        "    test_subset_fn, batch_size, 1,\n",
        "    input_size=input_size,\n",
        ")\n",
        "deeplabv3, w_dict = create_deeplabv3(input_size)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(lr=0.0001)\n",
        "deeplabv3.compile(\n",
        "    loss=ce_dice_loss_from_logits(num_classes),\n",
        "    optimizer=optimizer,\n",
        "    metrics=[\n",
        "        PixelAccuracyMetric(num_classes),\n",
        "        MeanIoUMetric(num_classes),\n",
        "        MeanAccuracyMetric(num_classes)\n",
        "    ])\n",
        "\n",
        "for k, w in w_dict.items():\n",
        "    deeplabv3.get_layer(k).set_weights(w)\n",
        "deeplabv3.summary()\n",
        "\n"
      ],
      "metadata": {
        "id": "2gLzDCZGL45M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kQ2cAWoLJjy"
      },
      "source": [
        "##Навчання моделі"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4YBdVaGYDd5z"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists('eval'):\n",
        "    os.mkdir('eval')\n",
        "\n",
        "if not os.path.exists('models'):\n",
        "    os.mkdir('models')\n",
        "\n",
        "csv_logger = tf.keras.callbacks.CSVLogger(os.path.join('eval','2_deeplab_v3.log'))\n",
        "monitor_metric = 'val_loss'\n",
        "mode = 'min' if 'loss' in monitor_metric else 'max'\n",
        "print(\"Using metric={} and mode={} for EarlyStopping\".format(monitor_metric, mode))\n",
        "\n",
        "lr_callback = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor=monitor_metric, factor=0.1, patience=3, mode=mode, min_lr=1e-8\n",
        ")\n",
        "t1 = time.time()\n",
        "\n",
        "deeplabv3.fit(\n",
        "    tr_image_ds, steps_per_epoch=n_train,\n",
        "    validation_data=val_image_ds, validation_steps=n_valid,\n",
        "    epochs=epochs, callbacks=[lr_callback, csv_logger]\n",
        ")\n",
        "t2 = time.time()\n",
        "print(\"It took {} seconds to complete the training\".format(t2-t1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdbr5XPALC_H"
      },
      "source": [
        "##Зберігання моделі Deeplabv3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VNg0BOizLC_H"
      },
      "outputs": [],
      "source": [
        "\n",
        "tf.keras.models.save_model(deeplabv3, os.path.join('models', 'deeplabv3.h5'))\n",
        "deeplabv3 = tf.keras.models.load_model(os.path.join('models', 'deeplabv3.h5'), compile=False)\n",
        "optimizer = tf.keras.optimizers.Adam(lr=0.0001)\n",
        "deeplabv3.compile(\n",
        "    loss=ce_dice_loss_from_logits(num_classes),\n",
        "    optimizer=optimizer,\n",
        "    metrics=[\n",
        "        MeanIoUMetric(num_classes),\n",
        "        MeanAccuracyMetric(num_classes),\n",
        "        PixelAccuracyMetric(num_classes)\n",
        "    ])\n",
        "deeplabv3.evaluate(test_image_ds, steps=n_valid)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXoAO7IeLC_I"
      },
      "source": [
        "## Вивід результатуючих зоборажень"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tlzG-LqJYWUE"
      },
      "outputs": [],
      "source": [
        "def generate_results_plot(image_ds, n, model):\n",
        "    plt.subplots(n//2, 4, figsize=(32,32))\n",
        "\n",
        "    i = 0\n",
        "    for img, y_true in image_ds.skip(220).take(n):\n",
        "        img_pred = model.predict(img, verbose=0)\n",
        "\n",
        "        y_pred = np.argmax(img_pred[0,:,:,:], axis=-1)\n",
        "        y_true = y_true.numpy().astype('int')\n",
        "\n",
        "        y_rgb_pred = rgb_image_from_pallette(y_pred)\n",
        "        y_rgb_true = rgb_image_from_pallette(y_true)\n",
        "\n",
        "        row = i // 2\n",
        "        col_off = (i % 2) * 2\n",
        "\n",
        "        plt.subplot(n//2, 4, row*4+col_off+1)\n",
        "        plt.imshow((img[0, :, :, :].numpy() * 255.0).astype('uint8'))\n",
        "        plt.axis('off')\n",
        "        if i < 2:\n",
        "            plt.title('Оригінальне зображення', fontsize=18)\n",
        "\n",
        "        plt.subplot(n//2, 4, row*4+col_off+2)\n",
        "        plt.imshow(y_rgb_pred.astype('uint8'))\n",
        "        plt.axis('off')\n",
        "        if i < 2:\n",
        "            plt.title('Результатуюче зображення', fontsize=18)\n",
        "        i += 1\n",
        "    plt.show()\n",
        "\n",
        "test_image_ds = generate_tf_dataset(\n",
        "    test_subset_fn, 1, 1,\n",
        "    input_size=(384,384))\n",
        "n=8\n",
        "generate_results_plot(test_image_ds, n, deeplabv3)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}